{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift elastic resize demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This demo shows how elastic resize can scale redshift cluster up or down with minimum impact for your workload\n",
    "    - Step 1, use query runner to simulate a continous workload\n",
    "    - Step 2, initiate elastic resize from AWS console, increase cluster size to 2x\n",
    "    - Step 3, start monitoring in notebook\n",
    "    - Step 4, Once resize is done, observe workload continuous, total cluster downtime is only a few minutes\n",
    "    - Step 5, Run the IO-heavy workload (like ETL), observe the performance is better than the original cluster\n",
    "    - Step 6, Show the number of slices is not changed after elastic resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "iamconnectioninfo = IamConnection()\n",
    "cluster_info = iamconnectioninfo.hostname_plus_port.split('.')\n",
    "clusterid = cluster_info[0]\n",
    "region = cluster_info[2]\n",
    "\n",
    "boto3.setup_default_session()\n",
    "client = boto3.client(service_name='redshift', region_name=region)\n",
    "\n",
    "start_time = time.time()\n",
    "print(time.ctime())\n",
    "\n",
    "# Monitor resizing status, check every 30 seconds\n",
    "for i in range(10*60):\n",
    "    response = client.describe_resize(\n",
    "        ClusterIdentifier=clusterid\n",
    "    )\n",
    "    print(response['Status'])\n",
    "    if response['Status'] == 'SUCCEEDED':\n",
    "        print('%s is completed successful at %s.' % (response['ResizeType'], time.ctime()))\n",
    "        print((time.time() - start_time)/60)\n",
    "        break\n",
    "    time.sleep(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code shows how to do elastic resize programmatically, so you can create a lambda function and schedule reoccurance, \n",
    "* e.g. sacle up for nightly ETL jobs, and scale down for day job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send resize request. Note\n",
    "# 1.5-2 minutes to size down\n",
    "# but 5-10 minutes to size up\n",
    "boto3.setup_default_session()\n",
    "client = boto3.client(service_name='redshift', region_name=region)\n",
    "\n",
    "response = client.resize_cluster(\n",
    "    ClusterIdentifier=clusterid,\n",
    "    ClusterType='multi-node',\n",
    "    NodeType='dc2.large',\n",
    "    NumberOfNodes=4,\n",
    "    Classic=False\n",
    ")\n",
    "print(response['Cluster']['ClusterStatus'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (rgsutils)",
   "language": "python",
   "name": "rgsutils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
